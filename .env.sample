# ============================================================
# MarkPDFDown Configuration
# ============================================================
# Usage:
#   1. cp .env.sample .env
#   2. Edit .env with your API keys
#   3. Run with Podman:
#      podman run -i --env-file .env docker.io/jorbenzhu/markpdfdown < input.pdf > output.md
#
# For parallel processing of large books, see README.md
# ============================================================

# ------------------------------------------------------------
# Provider Selection (choose one: openai, deepseek, gemini)
# ------------------------------------------------------------
LLM_PROVIDER=gemini

# ------------------------------------------------------------
# OpenAI Configuration
# ------------------------------------------------------------
# Uncomment and set if using OpenAI
# LLM_PROVIDER=openai
# OPENAI_API_KEY=sk-your-openai-key-here
# OPENAI_DEFAULT_MODEL=gpt-4o

# ------------------------------------------------------------
# DeepSeek Configuration (Cost-effective)
# ------------------------------------------------------------
# Uncomment and set if using DeepSeek
# LLM_PROVIDER=deepseek
# DEEPSEEK_API_KEY=sk-your-deepseek-key-here
# OPENAI_DEFAULT_MODEL=deepseek-chat

# ------------------------------------------------------------
# Google Gemini Configuration (Recommended for large documents)
# ------------------------------------------------------------
# Default provider - just set your API key
GEMINI_API_KEY=your-gemini-api-key-here
GEMINI_MODEL=gemini-2.5-flash

# ------------------------------------------------------------
# Advanced: OpenAI-Compatible API (Qwen, OpenRouter, etc.)
# ------------------------------------------------------------
# LLM_PROVIDER=openai
# OPENAI_API_KEY=your-api-key
# OPENAI_API_BASE=https://api.example.com/v1
# OPENAI_DEFAULT_MODEL=model-name
